##########################################################################################
##
## PAIRED T-TEST COMPARING TREE COUNTS IN GRIDDED FIELD SITE
## Author: Linda Luck 29 April 2020
##
##########################################################################################


### House keeping ----
## clean workspace
rm(list=ls())

## set working directory
setwd(dir)

## load libraries
if (!require(PairedData)) install.packages('PairedData')
if (!require(devtools)) install.packages('devtools')
if (!require(dplyr)) install.packages('dplyr')
if (!require(ggpubr)) install.packages('ggpubr')


## load data
df_10m <- read.csv(file = "raw/Litchie_grid_10m_2018_5cmDBH.csv", header = TRUE, strip.white = TRUE)#, row.names=1)
df_20m <- read.csv(file = "raw/Litchie_grid_20m_2018_5cmDBH.csv", header = TRUE, strip.white = TRUE)#, row.names=1)


## investigate data
str(df_10m)
str(df_20m)



### Summary statistics ----

## compare mean and SD for field and LiDAR counts - check for obvious differences
group_by(df_10m, group) %>%
  summarise(
    count = n(),
    mean = mean(trees, na.rm = TRUE),
    sd = sd(trees, na.rm = TRUE)
  )


group_by(df_20m, group) %>%
  summarise(
    count = n(),
    mean = mean(trees, na.rm = TRUE),
    sd = sd(trees, na.rm = TRUE)
  )

# --> mean & SD very similar for both grids



# Visualise data ----

ggboxplot(df_10m, x = "group", y = "trees", 
          color = "group", palette = c("#00AFBB", "#E7B800"),
          order = c("field", "LiDAR"),
          ylab = "n trees", xlab = "Groups") +
		  ggtitle("10 m grid")


ggboxplot(df_20m, x = "group", y = "trees", 
          color = "group", palette = c("#00AFBB", "#E7B800"),
          order = c("field", "LiDAR"),
          ylab = "n trees", xlab = "Groups") +
		  ggtitle("20 m grid")

		  

### Plot paired data ----
## --> check for parallel distribution

## 10m grid
# Subset trees counted in field sruvey
field_10m <- subset(df_10m,  group == "field", trees,
                 drop = TRUE)

# subset trees counted in LiDAR survey
LiDAR_10m <- subset(df_10m,  group == "LiDAR", trees,
                drop = TRUE)

# Plot paired data
pd_10m <- paired(field_10m, LiDAR_10m)
plot(pd_10m, type = "profile") + theme_bw()


## 20m grid
# Subset trees counted in field sruvey
field_20m <- subset(df_20m,  group == "field", trees,
                drop = TRUE)

# subset trees counted in LiDAR survey
LiDAR_20m <- subset(df_20m,  group == "LiDAR", trees,
                drop = TRUE)

# Plot paired data
pd_20m <- paired(field_20m, LiDAR_20m)
plot(pd_20m, type = "profile") + theme_bw()


### Check for normal distribution ----
## (usually only necessary for sample size n < 30)
## --> t-test can be used only when difference (d) is normally distributed

## compute the difference
d <- with(df_20m, 
          trees[group == "field"] - trees[group == "LiDAR"])
## Shapiro-Wilk normality test for the differences
shapiro.test(d)

# --> if p-value is greater than the significance level 0.05, then
# --> the distribution of the differences (d) are not significantly different from normal distribution
# --> I.e. we can assume the normality



### Paired sample t-test ----

## Compute t-test (data frame) 10 m grid
res_10m <- t.test(trees ~ group, data = df_10m, paired = TRUE)
res_10m 


# --> If the p-value of the test is less than the significance level alpha = 0.05 
# --> We can then reject null hypothesis and 
# --> conclude that field counts ARE significantly different from LiDAR counts
# --> e.g. p = 0.07247
# --> null hypothesis accepted
# --> Average tree count in field survey is not significantly different from average tree count in LiDAR survey with a p-value = 0.07247.


## Compute t-test (data frame) 20 m grid
res_20m <- t.test(trees ~ group, data = df_20m, paired = TRUE)
res_20m

# --> Average tree count in field survey is not significantly different from average tree count in LiDAR survey with a p-value = 0.0601.

##########################################################################################
##
## COMPARE DBH FROM FIELD SURVEY AND LIDAR SCANS
## Author: Linda Luck 04 Feb 2020
##
##########################################################################################


### House keeping ----
## clean workspace
rm(list=ls())
#ctrl+l

## set working directory
setwd(dir)

## load libraries
(!require(ggplot2)) install.packages('ggplot2')
(!require(car)) install.packages('car')
(!require(visreg)) install.packages('visreg')



## load data
df <- read.csv(file = "raw/P1_2018_LiDAR_survey_match.csv", header = TRUE, strip.white = TRUE)#, row.names=1)


## investigate data
str(df) # check variables are loaded in correct format
summary(df)


## convert DBH units
df$DBHm <- df$DBH.1/100 # convert manual DBH to m



### 1. Visualization of raw data and transform data if needed ----

## raw data plot with /without separating by species
ggplot(df,aes(y=DBHm,x=DBH))+ geom_point(color='blue') +
  geom_smooth(method='lm') + 
  theme(text = element_text(size=16)) +
  labs(title = "Field v. LiDAR DBH untransformed")+ xlab("LiDAR DBH")+ ylab("field DBH")

ggplot(df,aes(y=DBH.1,x=DBH))+ geom_point(color='blue') +
  geom_smooth(method='loess') + 
  theme(text = element_text(size=16)) +
  labs(title = "Field v. LiDAR DBH for each species untransformed")+ xlab("LiDAR DBH")+ ylab("field DBH")+
  facet_wrap(~Species.ID)


## histograms of variables
hist(df$DBH) # -> TLS DBH is a bit skewed but not too bad

hist(df$DBHm) # -> manual DBH is right skewed - might log transform?
df$LOG_DBHm <- log(df$DBHm)
hist(df$LOG_DBHm) # -> bit better but not much; still need to investigate model performance with raw and log transform (below)

## relationship btw log DBH field and scanner -> not really better
ggplot(df,aes(y=LOG_DBHm,x=DBH))+ geom_point(color='blue') +
  geom_smooth(method='lm') + 
  theme(text = element_text(size=16)) +
  labs(title = "test log-transform of skewed field DBH")+ xlab("LiDAR DBH")+ ylab("field DBH") 
# -> points now arch and don't align as well to the line
# -> doesn't explain data well
# -> raw fit might be better, even though skewed outcome



### 2. Summary statistics ----

## nonparametric Spearman correlations based on ranks
cor.test(df$DBHm,df$DBH, use="complete.obs", method="spearman") 
# -> highly significant p-value, rho (correlation coefficient) close to +1 indicates strong positive correlation



### 3. Regression model ----

## linear model of raw field DBH
m1 <- lm(DBHm ~ DBH, data=df) 
summary(m1)
# Coefficients:
#              Estimate Std. Error t value  Pr(>|t|)    
# DBH         1.051467   0.014135  74.386   <2e-16 ***
# -> coefficient estimate (1st column) means that for every 1 unit increase in DBHcm there is an average 1.05 unit increase in the DHBfield
confint(m1) # 95% CI indicates better fit for non-log model
#              2.5 %     97.5 %
# DBH         1.0236873307 1.079246940
# -> above means that for every unit increase in the DBHcm we are 95% confident that the increase is between 1.02 and 1.08 units in the DBHfield



### 4. Model diagnostics https://www.statmethods.net/stats/rdiagnostics.html ----

# check for a potential serial autocorrelation e.g. spatial autocorrelation
# simulating spatial proximity using coordinates
df_acf <- df
df_acf$XY <- df_acf$TreeLocationY-df_acf$TreeLocationX

(!require(tidyverse)) install.packages('tidyverse')

df_acf <- df_acf %>% arrange(XY) # re-order rows according to location
ggplot(df_acf, aes(x = TreeLocationX, y = TreeLocationY, color = XY, size = DBH)) + geom_point() + scale_color_gradientn(colours = rainbow(5)) + coord_fixed() # plot to check spatial gradient
m1_acf <- lm(DBHm ~ DBH, data=df_acf) # redo choson model with ordered data

par(mfrow=c(1,2))
acf(resid(m1_acf), main="autocorrelation")
# -> no patterns visible
acf(resid(m1_acf),800) # at 8 for the 2018 data
par(mfrow=c(1,1))
# -> looking at entire data set, still no patterns visible, majority within dotted line



### 5. Check for influential outliers ----
# -> check for random pattern of residuals across fitted values (should be evenly distributed with no obvious patterns)
# -> check for no outliers or overly influential observations with a lot of leverage and high Cooks distance

par(mfrow=c(2,2))
plot(m1) # two influential outliers spotted (way outside cooks distance). removing both
par(mfrow=c(1,1))

# remove outliers
df_OR <- df
df_OR <- df_OR[-(441),] # for next outlier remove one previous indicated as data set shifted with first removal
df_OR <- df_OR[-(448),] # approx 20 cm difference between manual and LiDAR - manual collection error suspected

# redo model without influential outliers
m1_OR <- lm(DBHm ~ DBH, data=df_OR)
summary(m1_OR)
confint(m1_OR)
# compare to first model
summary(m1)
confint(m1)

par(mfrow=c(2,2))
plot(m1_OR)
par(mfrow=c(1,1))
# -> no further influential outliers spotted


## plot with and without outliers using setablished models

par(mfrow=c(1,2))
visreg(m1, xvar="DBH", ylab="DBHm", points=list(cex=1))
visreg(m1_OR, xvar="DBH", ylab="DBHm", points=list(cex=1)) 
par(mfrow=c(1,1))

### an underbelly showing up in visreg and resdiuals for lower values
### -> try res plots against predictor

standard_res<-rstandard(m1_OR)
DBHfield<-df_OR$DBHm

ggplot(data.frame(DBHfield,standard_res),aes(x=DBHfield,y= standard_res))+ 
  geom_point() +
  geom_smooth() +
  labs(title = "Standardized residuals vs predictor")+ 
  theme_classic() +  theme(plot.title = element_text(hjust = 0.5)) + theme(text = element_text(size=15))

## -> Res vs predictor overall good
# -> straight line (no waves)
# -> no pattern
# -> small number of negative residuals on bottom left
# --> i.e. outcomes which were overestimated for DBHfield 0-10 i.e. smaller trees
# -> however, vast majority of observations are well fitted for smaller trees
# --> i.e. either model did not perform well for small minoirty of trees OR mesuring error for these individuals
# number of poor predictions negligible and not influential


### 6. Plot effect ----

# Generate new dataset which contains the explanatory variables in the lm()
preddata <- with(df_OR, 
                 data.frame(DBH = seq(min(DBH), max(DBH), length = 200))
)
head(preddata) # = randomly generated data set within minimum and maximum values of original data set and predetermined lentgh


## Generate dataset for model m1
preds <- predict(m1_OR, newdata = preddata, se.fit = TRUE)
critval <- 1.96 ## approx 95% CI
upr <- preds$fit + (critval * preds$se.fit)
lwr <- preds$fit - (critval * preds$se.fit)
fit <- preds$fit
preddata_m1 <- data.frame(DBH=preddata$DBH, fit=fit, lower=lwr, upper=upr)

## plot to compare model fit - raw / log
ggplot(aes(x=DBH, y=fit), data=preddata_m1) +
  geom_point(aes(x=DBH, y=DBHm), data=df_OR, size=2) +
  geom_line(aes(x=DBH, y=fit), data=preddata_m1, size=1) +
  geom_ribbon(data=preddata_m1,aes(ymin=lower,ymax=upper),alpha=0.3, fill="blue")+
  labs(x="DBH LiDAR", y="fitted DBH field") + theme_bw()



#### 7. Pretty plot ----

### replicate model in k-fold - allows to extract model errors
if (!require(caret)) install.packages('caret')

  
### resample data
set.seed(123)
train.control <- trainControl(method = "repeatedcv", 
                                number = 10, repeats = 3)
  
### train the model

set.seed(123)
m1_k <- train(DBHm ~ DBH, data = df_OR, method = "lm",
                        trControl = train.control)
  
## check that no difference
  
summary(m1_k)
summary(m1_OR) # compare to normal model, results should be identical
  
  
### export model performance metrics to figure label
  
summary_m1_k <- print(m1_k)
  
R2_m1 <- as.numeric(summary_m1_k[[2]])
lab_R2_m1 <- paste("R2 = ", format(round(R2_m1, 2), nsmall = 2))

RMSE_m1 <- as.numeric(summary_m1_k[[1]])
lab_RMSE_m1 <- paste("RMSE = ", format(round(RMSE_m1, 4), nsmall = 2), "m")

MAE_m1 <- as.numeric(summary_m1_k[[3]])
lab_MAE_m1 <- paste("MAE = ", format(round(MAE_m1, 4), nsmall = 2), "m")

lab_m1 <- paste(lab_R2_m1,lab_RMSE_m1,lab_MAE_m1, sep = "\n")


### plot results

ggplot(data = preddata_m1, aes(x = DBH, y = fit)) +
  geom_point(aes(x=DBH, y=DBHm), data=df_OR, alpha = 0.5) +
  geom_line(aes(x=DBH, y=fit), data=preddata_m1, size=0.5, color="blue") +
  geom_ribbon(data=preddata_m1,aes(ymin=lower,ymax=upper),alpha=0.3, fill="blue") +
  annotate(geom = "text", x = min(preddata_m1$DBH), y = max(preddata_m1$fit), 
           label = lab_m1, hjust = 0, vjust = 1.6, lineheight = 1, size = 5) +
  #ggtitle("pretty plot") +
  labs(x="DBH TLS (m)", y="DBH field (m)") +
  theme_light() +
  scale_x_continuous(limits = c(0,0.50), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0,0.50), expand = c(0, 0)) +
  theme(aspect.ratio = 1, 
  text=element_text(size=19))
  

if (!require(praise)) install.packages('praise')
praise()
