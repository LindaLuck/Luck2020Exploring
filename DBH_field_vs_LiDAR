##########################################################################################
##
## COMPARE DBH FROM FIELD SURVEY AND LIDAR SCANS
## Author: Linda Luck 04 Feb 2020
##
##########################################################################################


### House keeping ----
## clean workspace
rm(list=ls())
#ctrl+l

## set working directory
setwd(dir)

## load libraries
(!require(ggplot2)) install.packages('ggplot2')
(!require(car)) install.packages('car')
(!require(visreg)) install.packages('visreg')



## load data
df <- read.csv(file = "raw/P1_2018_LiDAR_survey_match.csv", header = TRUE, strip.white = TRUE)#, row.names=1)


## investigate data
str(df) # check variables are loaded in correct format
summary(df)


## convert DBH units
df$DBHm <- df$DBH.1/100 # convert manual DBH to m



### 1. Visualization of raw data and transform data if needed ----

## raw data plot with /without separating by species
ggplot(df,aes(y=DBH,x=DBHm))+ geom_point(color='blue') +
  geom_smooth(method='lm') + 
  theme(text = element_text(size=16)) +
  labs(title = "Field v. LiDAR DBH untransformed")+ xlab("LiDAR DBH")+ ylab("field DBH")

ggplot(df,aes(y=DBH,x=DBHm))+ geom_point(color='blue') +
  geom_smooth(method='loess') + 
  theme(text = element_text(size=16)) +
  labs(title = "Field v. LiDAR DBH for each species untransformed")+ xlab("LiDAR DBH")+ ylab("field DBH")+
  facet_wrap(~Species.ID)


## histograms of variables
hist(df$DBH) # -> TLS DBH is a bit skewed but not too bad

hist(df$DBHm) # -> manual DBH is right skewed - might log transform?
df$LOG_DBHm <- log(df$DBHm)
hist(df$LOG_DBHm) # -> bit better but not much; still need to investigate model performance with raw and log transform (below)

## relationship btw log DBH field and scanner -> not really better
ggplot(df,aes(y=DBH,x=LOG_DBHm))+ geom_point(color='blue') +
  geom_smooth(method='lm') + 
  theme(text = element_text(size=16)) +
  labs(title = "test log-transform of skewed field DBH")+ xlab("LiDAR DBH")+ ylab("field DBH") 
# -> points now arch and don't align as well to the line
# -> doesn't explain data well
# -> raw fit might be better, even though skewed outcome



### 2. Summary statistics ----

## nonparametric Spearman correlations based on ranks
cor.test(df$DBH,df$DBHm, use="complete.obs", method="spearman") 
# -> highly significant p-value, rho (correlation coefficient) close to +1 indicates strong positive correlation



### 3. Regression model ----

## linear model of raw field DBH
m1 <- lm(DBH ~ DBHm, data=df) 
summary(m1)
# Coefficients:
#               Estimate Std. Error t value Pr(>|t|)    
# (Intercept)   0.004395   0.001700   2.585   0.0101 *  
# DBHm          0.879817   0.011828  74.386   <2e-16 ***

# -> coefficient estimate (1st column) means that for every 1 unit increase in manual DBHm there is an average 0.88 unit increase in the TLS DHB


confint(m1) # 95% CI indicates better fit for non-log model
#               2.5 %      97.5 %
# (Intercept) 0.001053542 0.007735882
# DBHm        0.856572563 0.903062185

# -> above means that for every unit increase in the DBHm we are 95% confident that the increase is between 0.86 and 0.90 units in the TLS DBH



### 4. Model diagnostics https://www.statmethods.net/stats/rdiagnostics.html ----

# check for a potential serial autocorrelation e.g. spatial autocorrelation
# simulating spatial proximity using coordinates
df_acf <- df
df_acf$XY <- df_acf$TreeLocationY-df_acf$TreeLocationX

(!require(tidyverse)) install.packages('tidyverse')

df_acf <- df_acf %>% arrange(XY) # re-order rows according to location
ggplot(df_acf, aes(x = TreeLocationX, y = TreeLocationY, color = XY, size = DBHm)) + geom_point() + scale_color_gradientn(colours = rainbow(5)) + coord_fixed() # plot to check spatial gradient
m1_acf <- lm(DBH ~ DBHm, data=df_acf) # redo choson model with ordered data

par(mfrow=c(1,2))
acf(resid(m1_acf), main="autocorrelation")
# -> no patterns visible
acf(resid(m1_acf),800) # at 8 for the 2018 data
par(mfrow=c(1,1))
# -> looking at entire data set, still no patterns visible, majority within dotted line



### 5. Check for influential outliers ----
# -> check for random pattern of residuals across fitted values (should be evenly distributed with no obvious patterns)
# -> check for no outliers or overly influential observations with a lot of leverage and high Cooks distance

par(mfrow=c(2,2))
plot(m1) # two influential outliers spotted (way outside cooks distance). removing both
par(mfrow=c(1,1))

# remove outliers
df_OR <- df
df_OR <- df_OR[-(441),] # for next outlier remove one previous indicated as data set shifted with first removal
df_OR <- df_OR[-(448),] # approx 20 cm difference between manual and LiDAR - manual collection error suspected

# redo model without influential outliers
m1_OR <- lm(DBH ~ DBHm, data=df_OR)
summary(m1_OR)
confint(m1_OR)
# compare to first model
summary(m1)
confint(m1)

par(mfrow=c(2,2))
plot(m1_OR)
par(mfrow=c(1,1))
# -> no further influential outliers spotted


## plot with and without outliers using setablished models

par(mfrow=c(1,2))
visreg(m1, xvar="DBHm", ylab="DBH", points=list(cex=1))
visreg(m1_OR, xvar="DBHm", ylab="DBH", points=list(cex=1)) 
par(mfrow=c(1,1))

### a small number of outlying points showing up in visreg and resdiuals for lower values
### -> try res plots against predictor

standard_res<-rstandard(m1_OR)
DBH_TLS<-df_OR$DBH

ggplot(data.frame(DBH_TLS,standard_res),aes(x=DBH_TLS,y= standard_res))+ 
  geom_point() +
  geom_smooth() +
  labs(title = "Standardized residuals vs predictor")+ 
  theme_classic() +  theme(plot.title = element_text(hjust = 0.5)) + theme(text = element_text(size=15))

## -> Res vs predictor overall good
# -> fairly straight line (no strong waves)
# -> no pattern
# -> small number of residuals on top left
# --> i.e. outcomes which were underestimated for DBHfield 0-10 i.e. smaller trees
# -> however, vast majority of observations are well fitted for smaller trees
# --> i.e. either model did not perform well for small minoirty of trees OR mesuring error for these individuals
# number of poor predictions negligible and not influential


### 6. Plot effect ----

# Generate new dataset which contains the explanatory variables in the lm()
preddata <- with(df_OR, 
                 data.frame(DBHm = seq(min(DBHm), max(DBHm), length = 200))
)
head(preddata) # = randomly generated data set within minimum and maximum values of original data set and predetermined lentgh


## Generate dataset for model m1
preds <- predict(m1_OR, newdata = preddata, se.fit = TRUE)
critval <- 1.96 ## approx 95% CI
upr <- preds$fit + (critval * preds$se.fit)
lwr <- preds$fit - (critval * preds$se.fit)
fit <- preds$fit
preddata_m1 <- data.frame(DBHm=preddata$DBHm, fit=fit, lower=lwr, upper=upr)

## plot to compare model fit - raw / log
ggplot(aes(x=DBHm, y=fit), data=preddata_m1) +
  geom_point(aes(x=DBHm, y=DBH), data=df_OR, size=2) +
  geom_line(aes(x=DBHm, y=fit), data=preddata_m1, size=1) +
  geom_ribbon(data=preddata_m1,aes(ymin=lower,ymax=upper),alpha=0.3, fill="blue")+
  labs(x="field DBH", y="fitted DBH TLS") + theme_bw()

# -> model looks good


#### 7. Pretty plot ----

### replicate model in k-fold - allows to extract model errors
if (!require(caret)) install.packages('caret')

  
### resample data
set.seed(123)
train.control <- trainControl(method = "repeatedcv", 
                                number = 10, repeats = 3)
  
### train the model

set.seed(123)
m1_k <- train(DBH ~ DBHm, data = df_OR, method = "lm",
                        trControl = train.control)
  
## check that no difference
  
summary(m1_k)
summary(m1_OR) # compare to normal model, results should be identical
  
  
### export model performance metrics to figure label
  
summary_m1_k <- print(m1_k)
  
R2_m1 <- as.numeric(summary_m1_k[[2]])
lab_R2_m1 <- paste("R2 = ", format(round(R2_m1, 2), nsmall = 2))

RMSE_m1 <- as.numeric(summary_m1_k[[1]])
lab_RMSE_m1 <- paste("RMSE = ", format(round(RMSE_m1, 4), nsmall = 2), "m")

MAE_m1 <- as.numeric(summary_m1_k[[3]])
lab_MAE_m1 <- paste("MAE = ", format(round(MAE_m1, 4), nsmall = 2), "m")

lab_m1 <- paste(lab_R2_m1,lab_RMSE_m1,lab_MAE_m1, sep = "\n")


### plot results

ggplot(data = preddata_m1, aes(x = DBHm, y = fit)) +
  geom_point(aes(x=DBHm, y=DBH), data=df_OR, alpha = 0.5) +
  geom_line(aes(x=DBHm, y=fit), data=preddata_m1, size=0.5, color="blue") +
  geom_ribbon(data=preddata_m1,aes(ymin=lower,ymax=upper),alpha=0.3, fill="blue") +
  annotate(geom = "text", x = min(preddata_m1$DBH), y = max(preddata_m1$fit), 
           label = lab_m1, hjust = 0, vjust = 1.6, lineheight = 1, size = 5) +
  #ggtitle("pretty plot") +
  labs(x="DBH field (m)", y="DBH TLS (m)") +
  theme_light() +
  scale_x_continuous(limits = c(0,0.50), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0,0.50), expand = c(0, 0)) +
  theme(aspect.ratio = 1, 
  text=element_text(size=19))
  

if (!require(praise)) install.packages('praise')
praise()
